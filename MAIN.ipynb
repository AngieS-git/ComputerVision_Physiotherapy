{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk\n",
    "import time\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optical flow folder: RecordedVids/\n",
      "Contents of input folder: ['Video_001']\n",
      "Found 50 images belonging to 1 classes.\n",
      "4/4 [==============================] - 1s 239ms/step\n",
      "0: 46 times\n",
      "1: 4 times\n",
      "Counts list: [46  4]\n",
      "The exercise type is:  Lumbar Side Bends with 84.48% - 99.52% Confidence Level\n"
     ]
    }
   ],
   "source": [
    "class LucasKanade_OpticalFlow:\n",
    "    def __init__(self, video_path=None):\n",
    "        self.video_path = video_path\n",
    "        self.cap = cv2.VideoCapture(self.video_path) if self.video_path else None\n",
    "        self.output_folder = None\n",
    "        self.frame_count = 0\n",
    "        self.input_folder = None  # Added line\n",
    "\n",
    "    def create_output_folder(self):\n",
    "        folder_number = 1\n",
    "        while True:\n",
    "            current_folder = f'RecordedVids/Video_{folder_number:03d}'\n",
    "            if not os.path.exists(current_folder):\n",
    "                os.makedirs(current_folder)\n",
    "                self.output_folder = current_folder\n",
    "                break\n",
    "            else:\n",
    "                folder_number += 1\n",
    "\n",
    "    def detect_corners(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        corners = cv2.goodFeaturesToTrack(gray, maxCorners=3000, qualityLevel=0.001, minDistance=0.1)\n",
    "        return corners, gray\n",
    "\n",
    "    def calculate_optical_flow(self, prev_gray, gray, prev_pts):\n",
    "        new_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_pts, None, winSize=(25, 25), maxLevel=3,\n",
    "                                                        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "        flow_image = np.zeros_like(prev_gray)\n",
    "        for new, old in zip(new_pts, prev_pts):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            velocity_x = a - c\n",
    "            velocity_y = b - d\n",
    "            intensity = int(np.sqrt(velocity_x**2 + velocity_y**2) * 255 / 5)\n",
    "            color = (intensity, 0, 0)\n",
    "            flow_image = cv2.line(flow_image, (int(c), int(d)), (int(a), int(b)), color, 2)\n",
    "        return flow_image\n",
    "\n",
    "    def get_video_path(self):\n",
    "        file_path = filedialog.askopenfilename(title=\"Select Video File\", filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "        if file_path:\n",
    "            self.video_path = file_path\n",
    "            self.cap = cv2.VideoCapture(self.video_path)\n",
    "\n",
    "    def select_input_folder(self):\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()  # Hide the main window\n",
    "        self.input_folder = filedialog.askdirectory(title=\"Select Video Folder\")\n",
    "        if not self.input_folder:\n",
    "            print(\"No folder selected. Exiting.\")\n",
    "            self.input_folder = self.output_folder\n",
    "        else:\n",
    "            print(f\"Selected folder: {self.input_folder}\")\n",
    "\n",
    "    \n",
    "    def record_video(output_path='RecordedVids/output_video.mp4', duration=10):\n",
    "        cap = cv2.VideoCapture(0)  # 0 corresponds to the default camera\n",
    "\n",
    "        # Set the video resolution to 720p\n",
    "        cap.set(3, 1280)  # Width\n",
    "        cap.set(4, 720)   # Height\n",
    "\n",
    "        # Set the video codec and create a VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        fps = 21  # Frames per second\n",
    "        width, height = int(cap.get(3)), int(cap.get(4))\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "        # Display the countdown\n",
    "        for i in range(5, 0, -1):\n",
    "            print(f\"Recording starts in {i} seconds...\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        while time.time() - start_time < duration:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Error capturing frame.\")\n",
    "                break\n",
    "\n",
    "            # Display the frame (optional)\n",
    "            cv2.imshow('Recording', frame)\n",
    "\n",
    "            # Write the frame to the video file\n",
    "            out.write(frame)\n",
    "\n",
    "            # Break the loop if 'q' key is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        print(\"Recording complete!\")\n",
    "\n",
    "        # Release the VideoCapture and VideoWriter objects\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        # Close the OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    def classify_vid(self, progress_var):\n",
    "        self.get_video_path()\n",
    "        if not self.cap:\n",
    "            return\n",
    "        # adjust tkinter window to center\n",
    "        progress_window = tk.Toplevel()\n",
    "        progress_window.title(\"Optical Flow Conversion Progress\")\n",
    "        screen_width = progress_window.winfo_screenwidth()\n",
    "        screen_height = progress_window.winfo_screenheight()\n",
    "        x_coordinate = (screen_width - 500) // 2\n",
    "        y_coordinate = (screen_height - 500) // 2\n",
    "        progress_window.geometry(f\"500x200+{x_coordinate}+{y_coordinate}\")\n",
    "\n",
    "        progress_label = tk.Label(progress_window, text=\"Optical Flow Conversion Progress:\")\n",
    "        progress_label.pack(pady=10)\n",
    "\n",
    "        progress_bar = ttk.Progressbar(progress_window, variable=progress_var, length=200, mode='determinate')\n",
    "        progress_bar.pack(pady=10)\n",
    "\n",
    "        self.create_output_folder()\n",
    "\n",
    "        total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        ret, frame = self.cap.read()\n",
    "        prev_corners, prev_gray = self.detect_corners(frame)\n",
    "\n",
    "        while self.frame_count < 10:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            new_corners, gray = self.detect_corners(frame)\n",
    "            flow_image = self.calculate_optical_flow(prev_gray, gray, prev_corners)\n",
    "\n",
    "            cv2.imwrite(os.path.join(self.output_folder, f'optical_flow_{self.frame_count + 1:04d}.png'), flow_image)\n",
    "\n",
    "            progress_var.set(int((self.frame_count / total_frames) * 100))  # Update progress\n",
    "\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "            if k == 27 or k == ord('q'):  # 'q' key to quit\n",
    "                break\n",
    "\n",
    "            self.frame_count += 1\n",
    "            prev_gray = gray\n",
    "            prev_corners = new_corners.reshape(-1, 1, 2)\n",
    "\n",
    "            progress_window.update()\n",
    "\n",
    "        self.frame_count = 0\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        progress_window.destroy()\n",
    "\n",
    "        # Load the model\n",
    "        model_input_size = (224, 224, 3)\n",
    "        seed = 8\n",
    "        batch_size = 16  # Change this shit pag sasabog na yung GPU\n",
    "        exercise_type = ['LumbarSideBends', 'QuadrupedThoracicRotation', 'SupineNeckLift']\n",
    "\n",
    "        model = load_model(\"DemoModelFinal1.h5\")\n",
    "\n",
    "        inference_generator = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input,\n",
    "        )\n",
    "\n",
    "        curr_folder = self.output_folder\n",
    "\n",
    "        inference_direc = os.path.dirname(curr_folder)  # Get the parent directory of self.input_folder\n",
    "        inference_direc = os.path.join(inference_direc, '')  # Add an additional '/' at the end\n",
    "        inference_direc = inference_direc.replace(\"\\\\\", \"/\")  # Replace backslashes with forward slashes\n",
    "\n",
    "        print(f\"Using optical flow folder: {inference_direc}\")\n",
    "\n",
    "        # Print the contents of the input folder\n",
    "        print(f\"Contents of input folder: {os.listdir(inference_direc)}\")\n",
    "\n",
    "        inference_data = inference_generator.flow_from_directory(\n",
    "            inference_direc,\n",
    "            target_size=model_input_size[:2],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        prediction = model.predict(inference_data)\n",
    "        results = np.argmax(prediction, axis=1)\n",
    "        predicted_label = [exercise_type[i] for i in results]\n",
    "\n",
    "        def calculate_confidence_level(counts, confidence_level=95):\n",
    "            total = sum(counts)\n",
    "            max_index = counts.argmax()\n",
    "            part = counts[max_index]\n",
    "\n",
    "            percentage = (part / total) * 100\n",
    "\n",
    "            # Calculate standard error and margin of error for the confidence interval\n",
    "            standard_error = np.sqrt((percentage * (100 - percentage)) / total)\n",
    "            margin_of_error = standard_error * (1.96)  # Z-score for 95% confidence interval\n",
    "\n",
    "            lower_bound = max(0, percentage - margin_of_error)\n",
    "            upper_bound = min(100, percentage + margin_of_error)\n",
    "\n",
    "            return lower_bound, upper_bound\n",
    "\n",
    "        unique_values, counts = np.unique(results, return_counts=True)\n",
    "\n",
    "        for value, count in zip(unique_values, counts):\n",
    "            print(f\"{value}: {count} times\")\n",
    "\n",
    "        print(\"Counts list:\", counts)  # Print the items in counts[]\n",
    "\n",
    "        max_index = counts.argmax()\n",
    "        max_value = unique_values[max_index]\n",
    "\n",
    "        # Insert spaces before capital letters using a regular expression\n",
    "        spaced_exercise_type = [re.sub('([A-Z])', r' \\1', word) for word in exercise_type]\n",
    "\n",
    "        lower_bound, upper_bound = calculate_confidence_level(counts)\n",
    "        print(f\"The exercise type is: {spaced_exercise_type[max_value]} with {lower_bound:.2f}% - {upper_bound:.2f}% Confidence Level\")\n",
    "        cl = upper_bound\n",
    "        acc = lower_bound\n",
    "\n",
    "        self.results(self.video_path,spaced_exercise_type[max_value],acc,cl)\n",
    "        \n",
    "    def track_features(self):\n",
    "        self.get_video_path\n",
    "        if not self.cap:\n",
    "            return\n",
    "\n",
    "        ret, frame = self.cap.read()\n",
    "        prev_corners, prev_gray = self.detect_corners(frame)\n",
    "\n",
    "        while ret:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            new_corners, gray = self.detect_corners(frame)\n",
    "            flow_image = self.calculate_optical_flow(prev_gray, gray, prev_corners)\n",
    "\n",
    "            prev_gray = gray\n",
    "            prev_corners = new_corners.reshape(-1, 1, 2)\n",
    "\n",
    "            cv2.imshow('Optical Flow', flow_image)\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "            if k == 27 or k == ord('q'):  # 'q' key to quit\n",
    "                break\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def results(self, video_path, exercise_type, acc, confidence_level):\n",
    "        # Update the video path\n",
    "        self.video_path = video_path\n",
    "        self.cap = cv2.VideoCapture(self.video_path)\n",
    "\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error opening video file: {self.video_path}\")\n",
    "            return\n",
    "\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(\"Error reading frame.\")\n",
    "            return\n",
    "\n",
    "        prev_corners, prev_gray = self.detect_corners(frame)\n",
    "\n",
    "        while ret:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            new_corners, gray = self.detect_corners(frame)\n",
    "            flow_image = self.calculate_optical_flow(prev_gray, gray, prev_corners)\n",
    "\n",
    "            prev_gray = gray\n",
    "            prev_corners = new_corners.reshape(-1, 1, 2)\n",
    "\n",
    "            # Add text to the image\n",
    "            text = f\"The exercise type is: {exercise_type} at {acc:.2f}% with {confidence_level:.2f}% Confidence Level\"\n",
    "            position, font, font_scale, font_color, thickness = (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2\n",
    "\n",
    "            cv2.putText(flow_image, text, position, font, font_scale, font_color, thickness)\n",
    "            cv2.imshow('Optical Flow', flow_image)\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "            if k == 27 or k == ord('q'):  # 'q' key to quit\n",
    "                break\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "    def show_optical_flow_video(self):\n",
    "            self.get_video_path()\n",
    "            self.track_features()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Lucas-Kanade Optical Flow\")\n",
    "\n",
    "    screen_width = root.winfo_screenwidth()\n",
    "    screen_height = root.winfo_screenheight()\n",
    "    x_coordinate = (screen_width - 500) // 2\n",
    "    y_coordinate = (screen_height - 500) // 2\n",
    "    root.geometry(f\"500x200+{x_coordinate}+{y_coordinate}\")\n",
    "    feature_tracker = LucasKanade_OpticalFlow()\n",
    "\n",
    "    def record_video():\n",
    "        feature_tracker.record_video()\n",
    "    \n",
    "    def classify_exercise():\n",
    "        progress_var = tk.IntVar()\n",
    "        progress_var.set(0)\n",
    "        feature_tracker.classify_vid(progress_var)\n",
    "\n",
    "    def show_optical_flow():\n",
    "        feature_tracker.show_optical_flow_video()\n",
    "\n",
    "    def exit_application():\n",
    "        if root:\n",
    "            root.destroy()\n",
    "\n",
    "    btn_record_video = tk.Button(root, text=\"Record Exercise\", command=record_video)\n",
    "    btn_record_video.pack(pady=10)\n",
    "\n",
    "    btn_classify_exercise = tk.Button(root, text=\"Classify Exercise\", command=classify_exercise)\n",
    "    btn_classify_exercise.pack(pady=10)\n",
    "\n",
    "    btn_show_optical_flow = tk.Button(root, text=\"Show Optical Flow Video\", command=show_optical_flow)\n",
    "    btn_show_optical_flow.pack(pady=10)\n",
    "\n",
    "    btn_exit = tk.Button(root, text=\"Exit\", command=exit_application)\n",
    "    btn_exit.pack(pady=10)\n",
    "\n",
    "\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mrecord_camera\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 55\u001b[0m, in \u001b[0;36mrecord_camera\u001b[1;34m(duration, output_path)\u001b[0m\n\u001b[0;32m     52\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecording\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Write the frame to the video file\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Break the loop if 'q' key is pressed\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "def countdown_timer(window):\n",
    "    for i in range(5, 0, -1):\n",
    "        text = f\"Recording starts in {i} seconds...\"\n",
    "        cv2.putText(window, text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.imshow('Recording', window)\n",
    "        cv2.waitKey(1000)  # Wait for 1 second\n",
    "\n",
    "def record_camera(duration=10, output_path='RecordedVids/output_video.mp4'):\n",
    "    # Open the camera\n",
    "    cap = cv2.VideoCapture(0)  # 0 corresponds to the default camera\n",
    "\n",
    "    # Set the video resolution to 720p\n",
    "    cap.set(3, 1280)  # Width\n",
    "    cap.set(4, 720)   # Height\n",
    "\n",
    "    # Set the video codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = 21  # Frames per second\n",
    "    width, height = int(cap.get(3)), int(cap.get(4))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Capture a frame to get the window size\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error capturing frame.\")\n",
    "        return\n",
    "\n",
    "    # Create a window for the countdown\n",
    "    countdown_window = frame.copy()\n",
    "\n",
    "    # Start the countdown in a separate thread\n",
    "    countdown_thread = Thread(target=countdown_timer, args=(countdown_window,))\n",
    "    countdown_thread.start()\n",
    "\n",
    "    # Wait for the countdown to complete\n",
    "    countdown_thread.join()\n",
    "\n",
    "    # Start recording\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < duration:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error capturing frame.\")\n",
    "            break\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Recording', frame)\n",
    "\n",
    "        # Write the frame to the video file\n",
    "        out.write(frame)\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture and VideoWriter objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Close the OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    record_camera()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
