{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'D:\\MAPUA\\Thesis\\Video_Sample1\\Video1.mp4'\n",
    "\n",
    "# Parameters for Shi-Tomasi corner detection\n",
    "feature_params = dict(maxCorners=1000, qualityLevel=0.01, minDistance=10, blockSize=3)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=3, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Read the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# Create a background subtractor\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Read the first frame\n",
    "ret, prev_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect the arm region using color segmentation\n",
    "hsv_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2HSV)\n",
    "lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "arm_mask = cv2.inRange(hsv_frame, lower_skin, upper_skin)\n",
    "\n",
    "# Apply morphological operations to refine the mask\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "arm_mask = cv2.morphologyEx(arm_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Detect features in the arm region\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_gray, mask=arm_mask, **feature_params)\n",
    "\n",
    "# Create an empty mask for drawing purposes\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    # Read the current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = background_subtractor.apply(frame)\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform bitwise AND operation to extract arm regions\n",
    "    arm_mask = cv2.bitwise_and(fg_mask, gray)\n",
    "\n",
    "    # Track features using Lucas-Kanade optical flow\n",
    "    next_corners, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_corners, None, **lk_params)\n",
    "\n",
    "    # Filter out invalid and low-quality tracks\n",
    "    good_old = prev_corners[status == 1]\n",
    "    good_new = next_corners[status == 1]\n",
    "    good_err = err[status == 1]\n",
    "\n",
    "    # Refine feature set based on error threshold\n",
    "    good_old = good_old[good_err < 10]\n",
    "    good_new = good_new[good_err < 10]\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # Overlay the optical flow tracks on the frame\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('KLT Tracker', img)\n",
    "    if cv2.waitKey(int(1000 / cap.get(cv2.CAP_PROP_FPS))) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Update the previous frame, corners, and arm mask\n",
    "    prev_gray = gray.copy()\n",
    "    prev_corners = good_new.reshape(-1, 1, 2)\n",
    "    arm_mask = np.zeros_like(gray)\n",
    "    arm_mask = cv2.bitwise_or(arm_mask, arm_mask)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arm Tracking Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r'D:\\MAPUA\\Thesis\\Video_Sample1\\ArmTrack1.mp4'\n",
    "\n",
    "# Parameters for skin color segmentation\n",
    "lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "\n",
    "# Parameters for Shi-Tomasi corner detection\n",
    "feature_params = dict(maxCorners=1000, qualityLevel=0.01, minDistance=10, blockSize=3)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=3, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Read the video\n",
    "cap = cv2.VideoCapture('D:\\MAPUA\\Thesis\\Video_Sample1\\ArmTrack1.mp4')\n",
    "\n",
    "# Create a background subtractor\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Create an empty mask for drawing purposes\n",
    "mask = np.zeros((1, 1), dtype=np.uint8)\n",
    "\n",
    "# Initialize variables for KLT tracking\n",
    "prev_gray = None\n",
    "prev_points = None\n",
    "\n",
    "# Define a region of interest (ROI) for arm tracking\n",
    "roi_x, roi_y, roi_width, roi_height = 100, 100, 200, 200\n",
    "\n",
    "while True:\n",
    "    # Read the current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = background_subtractor.apply(frame)\n",
    "\n",
    "    # Convert the frame to HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Perform skin color segmentation to isolate arm regions\n",
    "    arm_mask = cv2.inRange(hsv_frame, lower_skin, upper_skin)\n",
    "\n",
    "    # Apply morphological operations to refine the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    arm_mask = cv2.morphologyEx(arm_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Define the ROI within the arm mask\n",
    "    roi = arm_mask[roi_y:roi_y + roi_height, roi_x:roi_x + roi_width]\n",
    "\n",
    "    # Detect corners within the ROI using Shi-Tomasi corner detection\n",
    "    corners = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "    if corners is not None:\n",
    "        # Adjust corner coordinates based on ROI position\n",
    "        corners = corners + np.array([roi_x, roi_y])\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if prev_gray is None:\n",
    "            # First frame, initialize previous frame and points\n",
    "            prev_gray = gray.copy()\n",
    "            prev_points = corners\n",
    "\n",
    "        else:\n",
    "            # Track features using Kanade-Lucas-Tomasi (KLT) tracker\n",
    "            next_points, status, _ = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None, **lk_params)\n",
    "\n",
    "            # Filter out invalid and low-quality tracks\n",
    "            good_prev = prev_points[status == 1]\n",
    "            good_next = next_points[status == 1]\n",
    "\n",
    "            # Draw optical flow lines on the frame\n",
    "            for (prev_x, prev_y), (next_x, next_y) in zip(good_prev, good_next):\n",
    "                cv2.arrowedLine(frame, (int(prev_x), int(prev_y)), (int(next_x), int(next_y)), (0, 255, 0), 2)\n",
    "\n",
    "            # Display the resulting image\n",
    "            cv2.imshow('Arm Tracking', frame)\n",
    "            if cv2.waitKey(int(1000 / cap.get(cv2.CAP_PROP_FPS))) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            # Update the previous frame and points\n",
    "            prev_gray = gray.copy()\n",
    "            prev_points = good_next\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
