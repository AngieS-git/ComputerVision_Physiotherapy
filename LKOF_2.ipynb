{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Code (cleaned up version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Point Coordinates:  471 283\n"
     ]
    }
   ],
   "source": [
    "def initialize_point():\n",
    "    # Point is initialized by clicking with the mouse\n",
    "    ix, iy = -1, -1  # Initialize coordinates\n",
    "    prompt_shown = False\n",
    "\n",
    "    def onMouse(event, x, y, flags, params):\n",
    "        nonlocal ix, iy, prompt_shown\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            ix, iy = x, y\n",
    "            prompt_shown = True\n",
    "\n",
    "    cv2.namedWindow(\"Camera\")\n",
    "    cv2.setMouseCallback(\"Camera\", onMouse)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    old_frame = None  # Initialize old_frame\n",
    "\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        if not prompt_shown:\n",
    "            font_scale = 0.7\n",
    "            font_color = (0, 225, 0)\n",
    "            font_thickness = 2\n",
    "            cv2.putText(frame, \"Select a point to track (left-click)\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        font_scale, font_color, font_thickness)\n",
    "\n",
    "        cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "        # Display coordinates on the camera frame\n",
    "        if ix != -1 and iy != -1:\n",
    "            cv2.circle(frame, (ix, iy), 5, (0, 225, 0), -1)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27 or prompt_shown:\n",
    "            break\n",
    "\n",
    "    old_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    old_points = np.array([[ix, iy]], dtype=\"float32\").reshape(-1, 1, 2)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return old_frame, old_points, ix, iy\n",
    "\n",
    "def track_point(old_frame, old_points, initial_x, initial_y):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        _, frame2 = cap.read()\n",
    "\n",
    "        if frame2 is None:  # Check if frame2 is valid\n",
    "            break\n",
    "\n",
    "        new_frame = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        new_points, status, error = cv2.calcOpticalFlowPyrLK(old_frame, new_frame, old_points,\n",
    "                                                             None, maxLevel=1,\n",
    "                                                             criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,\n",
    "                                                                       15, 0.08))\n",
    "\n",
    "        # Draw a slightly bigger dot at the new point\n",
    "        if status.ravel()[0] == 1:  # Check if the point is successfully tracked\n",
    "            x, y = new_points.ravel()\n",
    "            mask = np.zeros_like(frame2)\n",
    "            cv2.circle(mask, (int(x), int(y)), 5, (0, 255, 0), -1)  # Increase the radius to make it bigger\n",
    "            combined = cv2.addWeighted(frame2, 0.7, mask, 0.3, 0.1)\n",
    "\n",
    "            # Display coordinates of the selected point and tracking result\n",
    "            font_scale = 0.7\n",
    "            font_color = (0, 225, 0)\n",
    "            font_thickness = 1\n",
    "            cv2.putText(combined, f\"Initial Coordinates: ({initial_x}, {initial_y})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        font_scale, font_color, font_thickness)\n",
    "            \n",
    "            # Calculate and display live coordinates of the tracked point\n",
    "            live_x, live_y = int(x), int(y)\n",
    "            cv2.putText(combined, f\"Live Coordinates: ({live_x}, {live_y})\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        font_scale, font_color, font_thickness)\n",
    "            \n",
    "            cv2.imshow(\"Camera\", combined)\n",
    "\n",
    "        old_frame = new_frame.copy()\n",
    "        old_points = new_points.copy()\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:  # ESC key to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    old_frame, old_points, initial_x, initial_y = initialize_point()\n",
    "    print(\"Selected Point Coordinates: \", initial_x, initial_y)\n",
    "    track_point(old_frame, old_points, initial_x, initial_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three Points Tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Point Coordinates:  [(478, 161), (426, 148), (400, 169)]\n"
     ]
    }
   ],
   "source": [
    "def initialize_points(num_points):\n",
    "    # Initialize points list and counters\n",
    "    points = []\n",
    "    point_counter = 0\n",
    "\n",
    "    def onMouse(event, x, y, flags, params):\n",
    "        nonlocal point_counter\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            points.append((x, y))\n",
    "            point_counter += 1\n",
    "            if point_counter == num_points:\n",
    "                cv2.destroyWindow(\"Camera\")  # Close the camera window after selecting all points\n",
    "\n",
    "    cv2.namedWindow(\"Camera\")\n",
    "    cv2.setMouseCallback(\"Camera\", onMouse)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    old_frame = None  # Initialize old_frame\n",
    "\n",
    "    while point_counter < num_points:\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        # Display instructions for selecting points\n",
    "        font_scale = 0.7\n",
    "        font_color = (0, 225, 0)\n",
    "        font_thickness = 2\n",
    "        cv2.putText(frame, f\"Select {num_points} points to track (left-click)\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    font_scale, font_color, font_thickness)\n",
    "\n",
    "        # Draw circles on selected points\n",
    "        for point in points:\n",
    "            cv2.circle(frame, point, 5, (0, 0, 255), -1)  # Draw a red circle on each selected point\n",
    "\n",
    "        cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:  # ESC key to exit\n",
    "            break\n",
    "\n",
    "    old_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    old_points = np.array(points, dtype=\"float32\").reshape(-1, 1, 2)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return old_frame, old_points, points\n",
    "\n",
    "def track_points(old_frame, old_points, num_points, points):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        _, frame2 = cap.read()\n",
    "\n",
    "        if frame2 is None:  # Check if frame2 is valid\n",
    "            break\n",
    "\n",
    "        new_frame = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        new_points, status, error = cv2.calcOpticalFlowPyrLK(old_frame, new_frame, old_points,\n",
    "                                                             None, maxLevel=1,\n",
    "                                                             criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,\n",
    "                                                                       15, 0.08))\n",
    "\n",
    "        # Draw slightly bigger dots at the new points\n",
    "        for i in range(num_points):\n",
    "            if status.ravel()[i] == 1:  # Check if the point is successfully tracked\n",
    "                x, y = new_points[i].ravel()\n",
    "                mask = np.zeros_like(frame2)\n",
    "                cv2.circle(mask, (int(x), int(y)), 5, (0, 255, 0), -1)  # Increase the radius to make it bigger\n",
    "                frame2 = cv2.addWeighted(frame2, 0.7, mask, 0.3, 0.1)\n",
    "\n",
    "                # Display coordinates of the selected point and tracking result\n",
    "                font_scale = 0.7\n",
    "                font_color = (0, 225, 0)\n",
    "                font_thickness = 1\n",
    "                cv2.putText(frame2, f\"Point {i + 1} Coordinates: ({points[i][0]}, {points[i][1]})\", (10, 30 + i * 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_color, font_thickness)\n",
    "\n",
    "        cv2.imshow(\"Camera\", frame2)\n",
    "\n",
    "        old_frame = new_frame.copy()\n",
    "        old_points = new_points.copy()\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:  # ESC key to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_points = 3\n",
    "    old_frame, old_points, points = initialize_points(num_points)\n",
    "    print(\"Selected Point Coordinates: \", points)\n",
    "    track_points(old_frame, old_points, num_points, points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving Accuracy of Base Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Point Coordinates:  284 288\n"
     ]
    }
   ],
   "source": [
    "def initialize_point():\n",
    "    # Point is initialized by clicking with the mouse\n",
    "    ix, iy = -1, -1  # Initialize coordinates\n",
    "    prompt_shown = False\n",
    "\n",
    "    def onMouse(event, x, y, flags, params):\n",
    "        nonlocal ix, iy, prompt_shown\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            ix, iy = x, y\n",
    "            prompt_shown = True\n",
    "\n",
    "    cv2.namedWindow(\"Camera\")\n",
    "    cv2.setMouseCallback(\"Camera\", onMouse)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    old_frame = None  # Initialize old_frame\n",
    "\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        if not prompt_shown:\n",
    "            font_scale = 0.7\n",
    "            font_color = (0, 225, 0)\n",
    "            font_thickness = 2\n",
    "            cv2.putText(frame, \"Select a point to track (left-click)\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        font_scale, font_color, font_thickness)\n",
    "\n",
    "        cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "        # Display coordinates on the camera frame\n",
    "        if ix != -1 and iy != -1:\n",
    "            cv2.circle(frame, (ix, iy), 5, (0, 225, 0), -1)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27 or prompt_shown:\n",
    "            break\n",
    "\n",
    "    old_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    old_points = np.array([[ix, iy]], dtype=\"float32\").reshape(-1, 1, 2)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return old_frame, old_points, ix, iy\n",
    "\n",
    "def track_point(old_frame, old_points, initial_x, initial_y):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Increase the number of pyramid levels for more accurate tracking\n",
    "    max_level = 3\n",
    "\n",
    "    while True:\n",
    "        _, frame2 = cap.read()\n",
    "\n",
    "        if frame2 is None:  # Check if frame2 is valid\n",
    "            break\n",
    "\n",
    "        new_frame = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Increase the termination criteria values for accuracy\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01)\n",
    "\n",
    "        new_points, status, error = cv2.calcOpticalFlowPyrLK(old_frame, new_frame, old_points,\n",
    "                                                             None, maxLevel=max_level,\n",
    "                                                             criteria=criteria)\n",
    "\n",
    "        # Draw a slightly bigger dot at the new point\n",
    "        if status.ravel()[0] == 1:  # Check if the point is successfully tracked\n",
    "            x, y = new_points.ravel()\n",
    "            mask = np.zeros_like(frame2)\n",
    "            cv2.circle(mask, (int(x), int(y)), 15, (0, 255, 0), -1)  # Increase the radius to make it bigger\n",
    "            combined = cv2.addWeighted(frame2, 0.7, mask, 0.3, 0.1)\n",
    "\n",
    "            # Display coordinates of the selected point and tracking result\n",
    "            font_scale = 0.7\n",
    "            font_color = (0, 225, 0)\n",
    "            font_thickness = 1\n",
    "            cv2.putText(combined, f\"Initial Coordinates: ({initial_x}, {initial_y})\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        font_scale, font_color, font_thickness)\n",
    "            \n",
    "            # Calculate and display live coordinates of the tracked point\n",
    "            live_x, live_y = int(x), int(y)\n",
    "            cv2.putText(combined, f\"Live Coordinates: ({live_x}, {live_y})\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        font_scale, font_color, font_thickness)\n",
    "            \n",
    "            cv2.imshow(\"Camera\", combined)\n",
    "\n",
    "        old_frame = new_frame.copy()\n",
    "        old_points = new_points.copy()\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:  # ESC key to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    old_frame, old_points, initial_x, initial_y = initialize_point()\n",
    "    print(\"Selected Point Coordinates: \", initial_x, initial_y)\n",
    "    track_point(old_frame, old_points, initial_x, initial_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Detector using Shi-Tomasi (Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjii\\AppData\\Local\\Temp\\ipykernel_3020\\2348298210.py:12: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  corners = np.int0(corners)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"G:\\THESIS\\SampleImages\\SMTracking_LongSleeve.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "grayscale = cv2.cvtColor(image,  cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Perform Shi-Tomasi Corner Detection\n",
    "max_crnrs = 1500\n",
    "qual_lvl = 0.0001\n",
    "min_dist = 0.1\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(grayscale, maxCorners=max_crnrs, qualityLevel=qual_lvl, \n",
    "                                  minDistance=min_dist)\n",
    "corners = np.int0(corners)\n",
    "\n",
    "for corner in corners:\n",
    "    x, y = corner.ravel()\n",
    "    cv2.circle(image, (x, y), 3, (0, 255, 0), -1)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Shi-Tomasi Corner Detection', image)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modularize Shi_Tomasi function (not working yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shi_tomasi_corner_detection():\n",
    "    image_path = r'G:\\THESIS\\SampleImages\\SMTracking_LongSleeve.jpg'\n",
    "    image = cv2.imread(image_path)\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Parameters for Shi-Tomasi Corner Detection\n",
    "    max_crnrs = 1000\n",
    "    qual_lvl = 0.0001\n",
    "    min_dist = 0.1\n",
    "\n",
    "    # Detect Shi-Tomasi corners\n",
    "    corners = cv2.goodFeaturesToTrack(grayscale, maxCorners=max_crnrs, qualityLevel=qual_lvl,\n",
    "                                      minDistance=min_dist)\n",
    "    corners = np.int0(corners)\n",
    "\n",
    "    for corner in corners:\n",
    "        x, y = corner.ravel()\n",
    "        cv2.circle(image, (x, y), 3, (0, 255, 0), -1)\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow('Shi-Tomasi Corner Detection', image)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main\":\n",
    "    shi_tomasi_corner_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shi-Tomasi with WebCam or Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjii\\AppData\\Local\\Temp\\ipykernel_3028\\2469444226.py:34: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  corners = np.int0(corners)\n"
     ]
    }
   ],
   "source": [
    "def shi_tomasi_corner_detection(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    window_size = (1280, 720) \n",
    "    cv2.namedWindow('Shi-Tomasi Corner Detection', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Shi-Tomasi Corner Detection', *window_size)\n",
    "\n",
    "    frame_width = 640\n",
    "    frame_height = 360\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "\n",
    "    fps = 60 \n",
    "    frame_interval = 1.0 / fps\n",
    "\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        max_crnrs = 3000\n",
    "        qual_lvl = 0.001\n",
    "        min_dist = 0.1\n",
    "\n",
    "        corners = cv2.goodFeaturesToTrack(grayscale, maxCorners=max_crnrs, qualityLevel=qual_lvl,\n",
    "                                          minDistance=min_dist)\n",
    "\n",
    "        if corners is not None:\n",
    "            corners = np.int0(corners)\n",
    "\n",
    "            for corner in corners:\n",
    "                x, y = corner.ravel()\n",
    "                cv2.circle(frame, (x, y), 3, (0, 255, 0), -1)\n",
    "\n",
    "        cv2.imshow('Shi-Tomasi Corner Detection', frame)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time < frame_interval:\n",
    "            time.sleep(frame_interval - elapsed_time)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"G:\\THESIS\\SampleVideos\\SMTracking_TankTop.mp4\" \n",
    "    shi_tomasi_corner_detection(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrating LK and Shi-Tomasi Together [Draft 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def track_features(video_path):\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Parameters for Shi-Tomasi Corner Detection\n",
    "    max_corners = 3000\n",
    "    quality_level = 0.001\n",
    "    min_distance = 0.5\n",
    "\n",
    "    # Parameters for Lucas-Kanade Optical Flow\n",
    "    lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 12, 0.01))\n",
    "\n",
    "    # Read the first frame\n",
    "    ret, prev_frame = cap.read()\n",
    "    prev_frame = cv2.resize(prev_frame, (1280, 720))  # Resize the frame\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_pts = cv2.goodFeaturesToTrack(prev_gray, maxCorners=max_corners, qualityLevel=quality_level, minDistance=min_distance)\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (1280, 720))  # Resize the frame\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "        mask = np.zeros_like(prev_frame)\n",
    "\n",
    "        # Calculate optical flow using Lucas-Kanade\n",
    "        prev_frame = cv2.resize(prev_frame, (1280, 720))  # Resize the previous frame\n",
    "        new_pts, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_pts, None, **lk_params)\n",
    "\n",
    "        # Select only valid points\n",
    "        valid_new_pts = new_pts[status == 1]\n",
    "        valid_prev_pts = prev_pts[status == 1]\n",
    "\n",
    "        for i, (new, prev) in enumerate(zip(valid_new_pts, valid_prev_pts)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = prev.ravel()\n",
    "            a, b, c, d = int(a), int(b), int(c), int(d)  \n",
    "            \n",
    "            scaling_factor = 5 \n",
    "            a_new = int(a - (a - c) * scaling_factor)\n",
    "            b_new = int(b - (b - d) * scaling_factor)\n",
    "            \n",
    "            mask = cv2.line(mask, (a, b), (a_new, b_new), (0, 255, 0), 2)\n",
    "            frame = cv2.circle(frame, (a, b), 3, (0, 255, 0), -1)\n",
    "            \n",
    "\n",
    "        result = cv2.add(frame, mask)  \n",
    "\n",
    "        cv2.imshow('Frame', result)\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        \n",
    "        prev_gray = gray.copy()\n",
    "        prev_pts = valid_new_pts.reshape(-1, 1, 2)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"G:\\THESIS\\SampleVideos\\SMTracking_LongSleeve.mp4\"  \n",
    "    track_features(video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Draft 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def track_features(video_path):\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    max_corners = 3000\n",
    "    quality_level = 0.001\n",
    "    min_distance = 0.1 \n",
    "\n",
    "    # Parameters for Lucas-Kanade Optical Flow\n",
    "    lk_params = dict(winSize=(25, 25), maxLevel=3, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "\n",
    "    # Read the first frame\n",
    "    ret, prev_frame = cap.read()\n",
    "    prev_frame = cv2.resize(prev_frame, (1280, 720))  # Resize the frame\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    prev_pts = cv2.goodFeaturesToTrack(prev_gray, maxCorners=max_corners, qualityLevel=quality_level, minDistance=min_distance)\n",
    "\n",
    "    frame_width = 1280\n",
    "    frame_height = 720\n",
    "\n",
    "    # ROI\n",
    "    square_size = (670, 720) #ROI Size\n",
    "    square_x = int(frame_width - square_size[0]) // 2\n",
    "    square_y = int(frame_height - square_size[1]) // 2\n",
    "    square_position = (square_x, square_y) \n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (1280, 720)) \n",
    "\n",
    "        gray = cv2.cvtColor (frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Create a mask that covers the square ROI\n",
    "        mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "        x, y, w, h = square_position[0], square_position[1], square_size[0], square_size[1]\n",
    "        mask[y:y + h, x:x + w] = 230  \n",
    "\n",
    "        \n",
    "        masked_frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "        # Calculate optical flow using Lucas-Kanade on the masked_frame\n",
    "        prev_frame = cv2.resize(prev_frame, (1280, 720))  # Resize the previous frame\n",
    "        new_pts, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_pts, None, **lk_params)\n",
    "\n",
    "        valid_new_pts = new_pts[status == 1]\n",
    "        valid_prev_pts = prev_pts[status == 1]\n",
    "\n",
    "        for i, (new, prev) in enumerate(zip(valid_new_pts, valid_prev_pts)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = prev.ravel()\n",
    "            a, b, c, d = int(a), int(b), int(c), int(d)\n",
    "\n",
    "            if square_position[0] <= a <= square_position[0] + square_size[0] and square_position[1] <= b <= square_position[1] + square_size[1]:\n",
    "                scaling_factor = 5\n",
    "                a_new = int(a - (a - c) * scaling_factor)\n",
    "                b_new = int(b - (b - d) * scaling_factor)\n",
    "\n",
    "                #limit drawing to the ROI\n",
    "                mask = cv2.line(mask, (a, b), (a_new, b_new), (0, 255, 0), 2)\n",
    "                masked_frame = cv2.circle(masked_frame, (a, b), 3, (0, 255, 0), -1)\n",
    "\n",
    "        result = cv2.add(frame, masked_frame)\n",
    "\n",
    "        cv2.imshow('Frame', result)\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        prev_gray = gray.copy()\n",
    "        prev_pts = valid_new_pts.reshape(-1, 1, 2)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"G:\\THESIS\\SampleVideos\\SMTracking_LongSleeve.mp4\"\n",
    "    track_features(video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTracking:\n",
    "    def __init__(self, video_path):\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        self.max_corners =  3000\n",
    "        self.quality_level = 0.001\n",
    "        self.min_distance = 0.1\n",
    "\n",
    "        self.lk_params = dict(winSize=(25, 25), maxLevel= 3, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "\n",
    "        self.frame_width =  1280\n",
    "        self.frame_height = 720\n",
    "\n",
    "        #Region of Interest\n",
    "        self.square_size = (670, 720)\n",
    "        self.square_x = int(self.frame_width - self.square_size[0]) // 2 #since the square will be placed relative to the top left corner of the video\n",
    "        self.square_y = int(self.frame_height - self.square_size[1]) // 2 #we want to make sure that the ROI is placed in the middle\n",
    "        self.square_position = (self.square_x, self.square_y)\n",
    "\n",
    "    def process_video(self):\n",
    "        ret, prev_frame = self.cap.read()\n",
    "        prev_frame = cv2.resize(prev_frame, (self.frame_width, self.frame_height))  # Resize the frame\n",
    "        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        prev_pts = cv2.goodFeaturesToTrack(prev_gray, maxCorners=self.max_corners, qualityLevel=self.quality_level, minDistance=self.min_distance)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "\n",
    "            #convert to grayscale\n",
    "            frame  = cv2.resize(frame, (self.frame_width, self.frame_height))\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            #create ROI\n",
    "            mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "            x, y, w, h = self.square_position[0], self.square_position[1], self.square_size[0], self.square_size[1]\n",
    "            mask[y:y + h, x:x + w] = 230\n",
    "            masked_frame = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "            \n",
    "            # Calculate optical flow using Lucas-Kanade on the masked_frame\n",
    "            prev_frame = cv2.resize(prev_frame, (self.frame_width, self.frame_height))  # Resize the previous frame\n",
    "            new_pts, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_pts, None, **self.lk_params)\n",
    "\n",
    "            valid_new_pts = new_pts[status == 1]\n",
    "            valid_prev_pts = prev_pts[status == 1]\n",
    "\n",
    "            for i, (new, prev) in enumerate(zip(valid_new_pts, valid_prev_pts)):\n",
    "                a, b = new.ravel()\n",
    "                c, d = prev.ravel()\n",
    "                a, b, c, d = int(a), int(b), int(c), int(d)\n",
    "\n",
    "                if self.square_position[0] <= a <= self.square_position[0] + self.square_size[0] and self.square_position[1] <= b <= self.square_position[1] + self.square_size[1]:\n",
    "                    scaling_factor = 5\n",
    "                    a_new = int(a - (a - c) * scaling_factor)\n",
    "                    b_new = int(b - (b - d) * scaling_factor)\n",
    "\n",
    "                    #limit drawing to the ROI\n",
    "                    mask = cv2.line(mask, (a, b), (a_new, b_new), (0, 255, 0), 2)\n",
    "                    masked_frame = cv2.circle(masked_frame, (a, b), 3, (0, 255, 0), -1)\n",
    "\n",
    "            result = cv2.add(frame, masked_frame)\n",
    "\n",
    "            cv2.imshow('Frame', result)\n",
    "\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "\n",
    "            prev_gray = gray.copy()\n",
    "            prev_pts = valid_new_pts.reshape(-1, 1, 2)\n",
    "\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"G:\\THESIS\\SampleVideos\\SMTracking_LongSleeve.mp4\"\n",
    "    feature_tracker = FeatureTracking(video_path)\n",
    "    feature_tracker.process_video()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
