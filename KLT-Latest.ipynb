{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Code Kanade-Lucas-Tomasi Tracker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yango\\OneDrive\\Documents\\4th Year\\2nd Semester\\Thesis\\Thesis 2nd Test\\Latest.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yango/OneDrive/Documents/4th%20Year/2nd%20Semester/Thesis/Thesis%202nd%20Test/Latest.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Read the first frame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yango/OneDrive/Documents/4th%20Year/2nd%20Semester/Thesis/Thesis%202nd%20Test/Latest.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m ret, prev_frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yango/OneDrive/Documents/4th%20Year/2nd%20Semester/Thesis/Thesis%202nd%20Test/Latest.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m prev_gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(prev_frame, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yango/OneDrive/Documents/4th%20Year/2nd%20Semester/Thesis/Thesis%202nd%20Test/Latest.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Detect the arm region using color segmentation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yango/OneDrive/Documents/4th%20Year/2nd%20Semester/Thesis/Thesis%202nd%20Test/Latest.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m hsv_frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(prev_frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2HSV)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "video_path = r'D:\\MAPUA\\Thesis\\Video_Sample1\\Video1.mp4'\n",
    "\n",
    "# Parameters for Shi-Tomasi corner detection\n",
    "feature_params = dict(maxCorners=1000, qualityLevel=0.01, minDistance=10, blockSize=3)\n",
    "\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=3, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Read the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# Create a background subtractor\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Read the first frame\n",
    "ret, prev_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect the arm region using color segmentation\n",
    "hsv_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2HSV)\n",
    "lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "arm_mask = cv2.inRange(hsv_frame, lower_skin, upper_skin)\n",
    "\n",
    "# Apply morphological operations to refine the mask\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "arm_mask = cv2.morphologyEx(arm_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Detect features in the arm region\n",
    "prev_corners = cv2.goodFeaturesToTrack(prev_gray, mask=arm_mask, **feature_params)\n",
    "\n",
    "# Create an empty mask for drawing purposes\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    # Read the current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = background_subtractor.apply(frame)\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform bitwise AND operation to extract arm regions\n",
    "    arm_mask = cv2.bitwise_and(fg_mask, gray)\n",
    "\n",
    "    # Track features using Lucas-Kanade optical flow\n",
    "    next_corners, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_corners, None, **lk_params)\n",
    "\n",
    "    # Filter out invalid and low-quality tracks\n",
    "    good_old = prev_corners[status == 1]\n",
    "    good_new = next_corners[status == 1]\n",
    "    good_err = err[status == 1]\n",
    "\n",
    "    # Refine feature set based on error threshold\n",
    "    good_old = good_old[good_err < 10]\n",
    "    good_new = good_new[good_err < 10]\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # Overlay the optical flow tracks on the frame\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('KLT Tracker', img)\n",
    "    if cv2.waitKey(int(1000 / cap.get(cv2.CAP_PROP_FPS))) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Update the previous frame, corners, and arm mask\n",
    "    prev_gray = gray.copy()\n",
    "    prev_corners = good_new.reshape(-1, 1, 2)\n",
    "    arm_mask = np.zeros_like(gray)\n",
    "    arm_mask = cv2.bitwise_or(arm_mask, arm_mask)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tkinter Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical Flow video saved to C:\\Users\\yango\\OneDrive\\Documents\\4th Year\\2nd Semester\\Thesis\\Thesis 2nd Test\\OutputVideo_Sample1\\Video_19\\LK_Video_19.mp4\n"
     ]
    }
   ],
   "source": [
    "# Specify the video save directory\n",
    "video_save_directory = r'C:\\Users\\yango\\OneDrive\\Documents\\4th Year\\2nd Semester\\Thesis\\Thesis 2nd Test\\Video_Sample1'\n",
    "output_folder = r'C:\\Users\\yango\\OneDrive\\Documents\\4th Year\\2nd Semester\\Thesis\\Thesis 2nd Test\\OutputVideo_Sample1'\n",
    "\n",
    "# Create the main GUI window\n",
    "window = tk.Tk()\n",
    "window.title(\"Kanade-Lucas-Tomasi Tracking\")\n",
    "window.geometry(\"400x250\")\n",
    "\n",
    "window_width = 400\n",
    "window_height = 300\n",
    "\n",
    "# Calculate the screen dimensions\n",
    "screen_width = window.winfo_screenwidth()\n",
    "screen_height = window.winfo_screenheight()\n",
    "\n",
    "# Calculate the position for centering the window\n",
    "x = (screen_width - window_width) // 2\n",
    "y = (screen_height - window_height) // 2\n",
    "\n",
    "# Set the window geometry to center the window on the screen\n",
    "window.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
    "# Variable to store the video file name\n",
    "video_file_name = \"\"\n",
    "\n",
    "def start_recording():\n",
    "    global video_file_name\n",
    "    video_file_name = \"Video_\" + str(len(os.listdir(video_save_directory)) + 1) + \".mp4\"\n",
    "\n",
    "    # Prompt the user to select a video size\n",
    "    video_sizes = {\n",
    "        \"640x480\": (640, 480),\n",
    "        \"1280x720\": (1280, 720),\n",
    "        \"1920x1080\": (1920, 1080)\n",
    "    }\n",
    "    selected_size = tk.StringVar()\n",
    "    size_selection_window = tk.Toplevel(window)\n",
    "    size_selection_window.title(\"Select Video Size\")\n",
    "    size_selection_window.geometry(\"200x150\")\n",
    "    size_selection_label = tk.Label(size_selection_window, text=\"Select Video Size:\")\n",
    "    size_selection_label.pack(pady=10)\n",
    "    size_selection = tk.OptionMenu(size_selection_window, selected_size, *video_sizes.keys())\n",
    "    size_selection.pack(pady=10)\n",
    "\n",
    "    def start_recording_with_size():\n",
    "        size_selection_window.destroy()\n",
    "\n",
    "        # Get the selected video size\n",
    "        width, height = video_sizes[selected_size.get()]\n",
    "\n",
    "        # Start recording the video using the camera\n",
    "        video_path = os.path.join(video_save_directory, video_file_name)\n",
    "\n",
    "        # Define the codec and create a VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(video_path, fourcc, 20.0, (width, height))\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Display the recording timer on the frame\n",
    "            elapsed_time = time.time() - start_time\n",
    "            timer_text = f\"Recording Time: {int(elapsed_time)}s / 10s\"\n",
    "            cv2.putText(frame, timer_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow('Recording', frame)\n",
    "\n",
    "            # Write the frame to the video file\n",
    "            out.write(frame)\n",
    "\n",
    "            if elapsed_time >= 10:\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        messagebox.showinfo(\"Recording Finished\", \"Video recording has been completed.\")\n",
    "\n",
    "\n",
    "    start_button = tk.Button(size_selection_window, text=\"Start Recording\", command=start_recording_with_size)\n",
    "    start_button.pack(pady=10)\n",
    "\n",
    "def show_recordings():\n",
    "    os.startfile(video_save_directory)\n",
    "\n",
    "def get_optical_flow():\n",
    "    # Select the video to extract landmarks from\n",
    "    video_file = filedialog.askopenfilename(initialdir=video_save_directory, title=\"Select Video File\",\n",
    "                                            filetypes=((\"Video Files\", \"*.mp4\"), (\"All Files\", \"*.*\")))\n",
    "    if not video_file:\n",
    "        return\n",
    "\n",
    "    # Get the video file name and create the output folder\n",
    "    video_file_name = os.path.basename(video_file)\n",
    "    output_folder_path = os.path.join(output_folder, os.path.splitext(video_file_name)[0])\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "    # Parameters for Shi-Tomasi corner detection\n",
    "    feature_params = dict(maxCorners=1000, qualityLevel=0.01, minDistance=10, blockSize=3)\n",
    "\n",
    "    # Parameters for Lucas-Kanade optical flow\n",
    "    lk_params = dict(winSize=(50, 50), maxLevel=5, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03))\n",
    "\n",
    "    # Read the video\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    # Create a background subtractor\n",
    "    background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    # Read the first frame\n",
    "    ret, prev_frame = cap.read()\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect the arm region using color segmentation\n",
    "    hsv_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_skin = np.array([0, 10, 50], dtype=np.uint8)\n",
    "    upper_skin = np.array([15, 220, 220], dtype=np.uint8)\n",
    "    arm_mask = cv2.inRange(hsv_frame, lower_skin, upper_skin)\n",
    "\n",
    "\n",
    "    # Apply morphological operations to refine the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    arm_mask = cv2.morphologyEx(arm_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "\n",
    "    # Detect features in the arm region\n",
    "    prev_corners = cv2.goodFeaturesToTrack(prev_gray, mask=arm_mask, **feature_params)\n",
    "\n",
    "    # Create an empty mask for drawing purposes\n",
    "    mask = np.zeros_like(prev_frame)\n",
    "\n",
    "    # Output video path\n",
    "    output_video_filename = f\"LK_{os.path.splitext(video_file_name)[0]}.mp4\"\n",
    "    output_video_path = os.path.join(output_folder_path, output_video_filename)\n",
    "    output_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    output_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    output_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), output_fps, output_size)\n",
    "\n",
    "    while True:\n",
    "        # Read the current frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = background_subtractor.apply(frame)\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply a Gaussian blur to the mask.\n",
    "        arm_mask = cv2.GaussianBlur(arm_mask, (5, 5), 0) \n",
    "\n",
    "        # Perform bitwise AND operation to extract arm regions\n",
    "        arm_mask = cv2.bitwise_and(fg_mask, gray)\n",
    "\n",
    "        # Track features using Lucas-Kanade optical flow\n",
    "        next_corners, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_corners, None, **lk_params)\n",
    "\n",
    "        # Filter out invalid and low-quality tracks\n",
    "        good_old = prev_corners[status == 1]\n",
    "        good_new = next_corners[status == 1]\n",
    "        good_err = err[status == 1]\n",
    "\n",
    "        # Refine feature set based on error threshold\n",
    "        good_old = good_old[good_err < 10]\n",
    "        good_new = good_new[good_err < 10]\n",
    "\n",
    "        # Draw the tracks\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)\n",
    "            frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "        # Overlay the optical flow tracks on the frame\n",
    "        img = cv2.add(frame, mask)\n",
    "\n",
    "        # Write frame to the output video\n",
    "        output_writer.write(img)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow('KLT Tracker', img)\n",
    "        if cv2.waitKey(int(1000 / output_fps)) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update the previous frame, corners, and arm mask\n",
    "        prev_gray = gray.copy()\n",
    "        prev_corners = good_new.reshape(-1, 1, 2)\n",
    "        arm_mask = np.zeros_like(gray)\n",
    "        arm_mask = cv2.bitwise_or(arm_mask, arm_mask)\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    output_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Optical Flow video saved to {output_video_path}\")\n",
    "\n",
    "def view_OpticalFlow():\n",
    "    # Open the output f older containing the extracted landmarks\n",
    "    os.startfile(output_folder)\n",
    "\n",
    "def exit_program():\n",
    "    window.destroy()\n",
    "\n",
    "def on_closing():\n",
    "    # Delete the recorded video file if the GUI window is closed\n",
    "    global video_file_name\n",
    "    if video_file_name:\n",
    "        video_path = os.path.join(video_save_directory, video_file_name)\n",
    "        if os.path.exists(video_path):\n",
    "            os.remove(video_path)\n",
    "    window.destroy()\n",
    "\n",
    "# Bind the window closing event to the on_closing function\n",
    "window.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "\n",
    "# Create buttons for recording, viewing recordings, extracting landmarks, and exiting\n",
    "record_button = tk.Button(window, text=\"Start Recording\", command=start_recording)\n",
    "record_button.pack(pady=10)\n",
    "\n",
    "view_button = tk.Button(window, text=\"View Recordings\", command=show_recordings)\n",
    "view_button.pack(pady=10)\n",
    "\n",
    "get_OpticalFlow_button = tk.Button(window, text=\"Get Optical Flow\", command=get_optical_flow)\n",
    "get_OpticalFlow_button.pack(pady=10)\n",
    "\n",
    "# Create the \"View Extracted Landmarks\" button\n",
    "view_OpticalFlow_button = tk.Button(window, text=\"View Optical Flow\", command=view_OpticalFlow)\n",
    "view_OpticalFlow_button.pack(pady=10)\n",
    "\n",
    "exit_button = tk.Button(window, text=\"Exit\", command=exit_program)\n",
    "exit_button.pack(pady=10)\n",
    "\n",
    "# Run the GUI main loop\n",
    "window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
